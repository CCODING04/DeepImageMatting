{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度抠图( Deep Image Matting )算法分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以前的抠图算法有两个主要缺陷:  \n",
    "\n",
    "1. 只使用了浅层的特征 ( 比如颜色的像素值以及位置信息 )\n",
    "2. 缺乏高层的背景知识 ( 一副图像单看像素肯定看不出是什么，只有从全局看才能判断是什么物体 )  \n",
    "\n",
    "本文工作分为两部分，第一部分为深度卷积自编码( Deep convolutional encoder-decoder network ): 输入一张图片输出该图片的三元图( 即前景+背景+alpha蒙版 ). 第二部分是一个较小的卷积网络，对第一部分网络输出的alpha通道做了精化处理，使得结果拥有更精确的alpha值以及更明显的边缘。此外，本文建立一个49300张训练图像组成的大型抠图数据库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统抠图算法主要依据下面这个公式:  \n",
    "\n",
    "$$I_i = \\alpha_iF_i + ( 1 - \\alpha_i)B_i　　\\alpha_i\\in[0,1]$$\n",
    "  \n",
    "然而这个式子，对于每个像素值来说，有7个限定条件下的未知值需要求解，却只有通过三个已知值来求得。  \n",
    "关于为什么是7个值和3个值，这里很好理解的是有色图像每个像素点是由R、G、B三通道组成，对于未知的前景和背景来说一共有6个未知的值(即2x3)，再加上$\\alpha$，一共有7个未知值。而已知的只有该像素点的像素值（三通道R、G、B）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而这个方法仍然有很大的局限性:  \n",
    "\n",
    "1. 当前方法的设计是为了解决上面的等式，而上述等式是假设是基于两种颜色线性组合的前提的。而目前大部分算法都是将其视为颜色问题。常用的做法是提取出图像的前景色和背景色，然后根据上述的公式求出alpha值，又或者将两种颜色混合。这类方法很大程度上依赖颜色作为划分的特征（也会时常加入像素的空间信息，即将坐标作为特征加入），但是无法处理前景和背景重叠的情况（文中用到了incrediblely sensitive）。而实际上这类图片在自然图片中很常见。而这类方法通常需要后续人工的精化处理才能满足要求。\n",
    "2. 用来作抠图的数据集实在太小了。（然后吐槽了下现在做的抠图数据集，包括视频的）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文的方法是用输入图片和三元图(不懂是不是跟Closed-Form-Matting一样需要，理论是不需要的)通过深度学习计算得出alpha图层。两个部分的网络结构，第一部分是encoder-decoder网络，紧接着是一个小的残差网络，用来精化包括了整体的损失和alpha图层的损失。该方法是第一个提出使用图像和三元图配合端到端来学习alpha图层的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orz  \n",
    "搞什么，还是要trimap，无力吐槽了  \n",
    "难怪后面MIT的semantic image matting出来欢呼更高点，你需要trimap不就多了个处理步骤么，人类文明的进步就是为了更懒，所以这篇论文10分给5分吧，我看下接下来算法理论推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 相关工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 基于采样的(sampling-based methods)\n",
    "2. 传播方法(propagation methods)  \n",
    "上述关于前景背景$\\alpha$的式子重新设计成允许alpha值从已知的前景、背景区域过渡到未知区域。这类方法比较熟知的是closed-form-matting\n",
    "3. 深度学习(deep learning methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 新的抠图数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个用来训练的trimap都是通过实际的trimap随机膨胀得到的  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 方法详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一部分是deep convolutional encoder-decoder network  \n",
    "第二部分是small fully convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Matting encoder-decoder stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(等等…… 看到一篇《deep potrait matting》，我先读一下过会儿来继续)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
